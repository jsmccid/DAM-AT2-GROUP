---
title: "R Notebook"
output: html_notebook
---

```{r} 
library(tidyverse)
library(reshape2)
library(recommenderlab)
library(lubridate)
library(forcats)
library(caret)
library(ggridges)
```

#Data Cleaning
```{r}
# get data from refined file given
train <- readRDS('AT2_train_STUDENT.rds')


# train <- train %>% 
#   mutate(user_id = as.numeric(user_id)) %>% 
#   mutate(item_id = as.numeric(item_id)) 


  

raw <- readRDS('train_raw.rds')

scrape <- readRDS('scrape.rds')

genres <- colnames(train)[13:31]

#cluster movies by scrape and raw data adn get averages for each movies

#first get data and clean it for clustering
movies <- raw %>% 
  select(-c(user_id,age,gender,zip_code,occupation,rating,timestamp,movie_title,video_release_date,imdb_url)) %>% 
  left_join(scrape,by = c("item_id" = "movie_id")) %>% 
  distinct() %>% 
  select(-c(url,movie_code)) %>% 
  mutate_if(is.logical,as.factor) %>% 
  mutate(mature_rating = as.factor(mature_rating))%>% 
  mutate(item_id=as.factor(item_id)) %>% 
  mutate(release_date = as.numeric(release_date)) %>% 
  mutate_if(is.integer,as.numeric)

#preporcess fore cluster
movie_pre <- preProcess(movies, method = "medianImpute")
movies <- predict(movie_pre, newdata = movies)

movies_dum <- dummyVars(~.,data = movies %>% select(-item_id), fullRank = T)
movies_matrix <- predict(movies_dum, newdata = movies %>% select(-item_id))
#cluster into 100 groups
move_clus <- kmeans(movies_matrix,50,nrow(movies))


#combine cluster to average ratings or fill thme with 3.52 (mean of ratings) if none filled
movies <- movies %>%
  select(item_id)
movies$m_cluster <- move_clus$cluster
train <- train %>% 
  full_join(movies)

mean_rating<-mean(train$rating)
m_ratings <- train %>% 
  select(c(item_id,m_cluster,rating)) %>% 
  group_by(item_id,m_cluster) %>% 
  summarise(m_cluster_rating = mean(rating)) %>% 
  ungroup() 
train <-train %>% 
  left_join(m_ratings) %>% 
  mutate(m_cluster_rating = if_else(is.na(m_cluster_rating),mean_rating,m_cluster_rating))

####now do the same but cluster users instead of movies and for each get an mena rating from them###

users <- raw %>% 
  select(c(user_id:zip_code)) %>% 
  distinct() %>% 
  mutate(user_id=as.factor(user_id)) %>% 
  mutate(occupation = as.factor(occupation)) %>% 
  mutate(zip_code = as.factor(zip_code))

#preporcess fore cluster
users_pre <- preProcess(users, method = "medianImpute")
users <- predict(users_pre, newdata = users)

users_dum <- dummyVars(~.,data = users %>% select(-user_id), fullRank = T)
users_matrix <- predict(users_dum, newdata = users %>% select(-user_id))
#cluster into 100 groups
users_clus <- kmeans(users_matrix,50,nrow(users))

users <- users %>%
  select(user_id)

users$u_cluster <- users_clus$cluster
train <- train %>% 
  full_join(users)

u_ratings <- train %>% 
  select(c(user_id,u_cluster,rating)) %>% 
  group_by(user_id,u_cluster) %>% 
  summarise(u_cluster_rating = mean(rating)) %>% 
  ungroup() 
train <-train %>% 
  left_join(u_ratings) %>% 
  mutate(u_cluster_rating = if_else(is.na(u_cluster_rating),mean_rating,u_cluster_rating))
 



#merge with zipcodes to get state/place names
ZipCodeSourceFile = "http://download.geonames.org/export/zip/US.zip"
temp <- tempfile()
download.file(ZipCodeSourceFile , temp)
ZipCodes <- read.table(unz(temp, "US.txt"), sep="\t")
unlink(temp)
names(ZipCodes) = c("CountryCode", "zip_code", "PlaceName", 
                    "State", "AdminCode1", "AdminName2", "AdminCode2", 
                    "AdminName3", "AdminCode3", "latitude", "longitude", "accuracy")

ZipCodes <- ZipCodes %>%  
  mutate(State = as.character(State)) %>% 
  mutate(State = if_else(State =="","Military",State)) %>% 
  select(c(zip_code,State)) 
  

#missing zipcodes  and fixes
#https://en.wikipedia.org/wiki/List_of_ZIP_Code_prefixes
bad_zip <-str_split("0  2146  2154  2159  2320  5779  20707  20770 33205 41850 46005 51157 54248 60005 60007 60008 60035 60067  60089 60090 60115 60135 60152 60187 60201 60202 60302 60402 60466 60476 60515 60613 60614 60615 60626 60630  60641 60657 60659 60804 61401 61455 61801 61820 62522 62901 62903 66315 91919 93055"," +")[[1]]    
bad_zip <- as.integer(bad_zip)


bad_state<-case_when(
  bad_zip > 1000 & bad_zip < 2800 ~ 'Massachusetts',
  bad_zip == 5779 ~ 'Vermont',
  bad_zip > 20700 & bad_zip< 20800 ~ 'Maryland',
  bad_zip == 33205 ~ 'Florida',
  bad_zip == 41850 ~ 'Kentucky',
  bad_zip == 46005 ~ 'Indiana',
  bad_zip == 51157 ~ 'Iowa',
  bad_zip == 54248 ~ 'Wisconsin',
  bad_zip > 60000 & bad_zip < 63000 ~ 'Illinois',
  bad_zip > 90000 & bad_zip < 96200 ~ 'California',
  TRUE ~ 'Unknown'
)

bad_df <- data.frame(
  zip_code = bad_zip,
  State = bad_state
)
ZipCodes <- bind_rows(ZipCodes,bad_df)



train <- train %>% 
  mutate(zip_code = as.integer(as.character(zip_code))) %>% 
  left_join(ZipCodes) %>%
  mutate(State = if_else(is.na(State),"Unknown",State)) %>%
  select(-zip_code)


#Reviews per user
reviews <- train %>% 
  group_by(user_id) %>% 
  summarise(reviews = n())


# Mean rating per User
user_means <- train %>% 
  group_by(user_id) %>% 
  summarise(user_mean_rating = mean(rating))

#Check if movie was released before reviwers (mild assumption that age is accurate in June 1998)
train <- train %>% 
  mutate(older_than_reviewer = (1998 -age - year(release_date)) >= 0) %>% 
  mutate(age_diff = abs(1998 -age - year(release_date)))

# - User Age band/Gener ratings per item
user_age_gender_means <- train %>% 
  group_by(age_band,gender, item_id) %>% 
  summarise(user_age_band_gender_item_mean_rating = mean(rating)) %>% 
  ungroup() 


#Get most watched genre of movie and comapre it to movie being revied

#first get genres of movie
genre_tab<-train %>% 
  gather(genre,is_off,unknown:western) %>% 
  filter(is_off == T) %>% 
  select(c(item_id,movie_title,user_id,genre))

#then get most reviwed genres of each user
most_favoured<-train %>% 
  group_by(user_id) %>% 
  summarise_if(is.logical,sum) %>% 
  gather(most_reviewed,count,unknown:western) %>%
  group_by(user_id) %>% 
  filter(count == max(count)) %>% 
  select(user_id,most_reviewed) 

#finally, join to train set
train <- most_favoured%>% 
  inner_join(genre_tab, by = c('user_id' = 'user_id')) %>% 
  mutate(favoured = (genre == most_reviewed)) %>% 
  group_by(user_id,item_id) %>% 
  summarise(favoured = any(favoured == T)) %>% 
  full_join(train,by = c('user_id' = 'user_id','item_id' = 'item_id')) %>% 
  ungroup()

#See if staf prefer thsi movie over teh population and also join everything
train <-train %>% 
  mutate(staff_prefered = !is.na(item_imdb_staff_average) &(item_mean_rating < item_imdb_staff_average))%>% 
  inner_join(user_means, by = c('user_id' = 'user_id'))%>% 
  inner_join(reviews, by = c('user_id' = 'user_id'))%>% 
  inner_join(user_age_gender_means, by = c('item_id','age_band','gender'))

#general clean up
train <- train %>% select(-c(movie_title,video_release_date,imdb_url))




test <- readRDS('AT2_test_STUDENT.rds')
# test <- test %>% 
#   mutate(user_id = as.numeric(user_id)) %>% 
#   mutate(item_id = as.numeric(item_id)) 

#repeating process for test data
genre_tab_test<-test %>% 
  gather(genre,is_off,unknown:western) %>% 
  filter(is_off == T) %>% 
  select(c(item_id,movie_title,user_id,genre))

test <- most_favoured%>% 
  inner_join(genre_tab_test, by = c('user_id' = 'user_id')) %>% 
  mutate(favoured = (genre == most_reviewed)) %>% 
  group_by(user_id,item_id) %>% 
  summarise(favoured = any(favoured == T)) %>% 
  full_join(test,by = c('user_id' = 'user_id','item_id' = 'item_id'))%>% 
  ungroup() %>% 
  mutate(staff_prefered = !is.na(item_imdb_staff_average) &(item_mean_rating < item_imdb_staff_average))%>% 
  mutate(older_than_reviewer = (1998 -age - year(release_date)) >= 0) %>% 
  mutate(age_diff = abs(1998 -age - year(release_date))) %>% 
  left_join(user_means, by = c('user_id' = 'user_id'))%>% 
  inner_join(reviews, by = c('user_id' = 'user_id'))%>% 
  left_join(user_age_gender_means, by = c('item_id','age_band','gender'))

test <- test %>% 
  mutate(zip_code = as.integer(as.character(zip_code))) %>% 
  left_join(ZipCodes) %>% 
  mutate(State = if_else(is.na(State),"Unknown",State)) %>%
  select(-zip_code)

test <- test %>% 
  inner_join(users)

test <- test %>% 
  inner_join(movies)

test <-test %>% 
  left_join(u_ratings) %>% 
  mutate(u_cluster_rating = if_else(is.na(u_cluster_rating),mean_rating,u_cluster_rating))


test <-test %>% 
  left_join(m_ratings) %>% 
  mutate(m_cluster_rating = if_else(is.na(m_cluster_rating),mean_rating,m_cluster_rating))

test <- test %>% select(-c(movie_title,video_release_date,imdb_url))


saveRDS(train, 'better_train.rds')
saveRDS(test, 'better_test.rds')
rm(list=ls())

```

#EDA
```{r}
old <- readRDS('AT2_train_STUDENT.rds')


genres <- colnames(old)[13:31]

graph_dir = "graphs/"
rm(old)

df <- readRDS('better_train.rds')

df <- df %>% 
  mutate(age_band = as.character(age_band))


df$age_band[df$age_band == "under_18"]= "< 18 yrs"
df$age_band[df$age_band == "18_to_29"]= "18-29 yrs"
df$age_band[df$age_band == "30_to_44"]= "30-44 yrs"
df$age_band[df$age_band == "45_and_over"]= "> 45 yrs"



#Count Graphs for reviews
for (var in c("favoured","rating","item_imdb_mature_rating")){
  title <- paste("Count of", var)
  ggplot(df,aes_string(x = var)) + geom_bar() +
    labs(x = var,y = "Count") + ggtitle(title)
  unlink(paste(graph_dir,title,".png",sep = ""))
  ggsave(paste(graph_dir,title,".png",sep = ""))
}

#check user base in more detal
user_base <- df %>% 
  select(user_id,age_band,occupation,gender,State) %>% 
  distinct()

ggplot(user_base,aes(x = gender)) + geom_bar() +
  facet_wrap(age_band~.)+
  labs(title = "Counts of users by age band and gender",x = 'Gender',y = "Count") 
unlink(paste(graph_dir,"Counts of users by age_band and gender.png",sep = ""))
ggsave(paste(graph_dir,"Counts of users by age_band and gender.png",sep = ""))

#check user ratings in more detail
ggplot(df %>% 
         select(c(user_id,age_band,user_mean_rating,gender)) %>%
       distinct(),aes(y=user_mean_rating, x= gender)) + geom_boxplot() + facet_wrap(~age_band) + 
  labs(x = "Gender",y= "Mean rating") + ggtitle("Average ratings by\nAge band & Gender")
unlink(paste(graph_dir,"Mean ratings by age_band and gender.png",sep = ""))
ggsave(paste(graph_dir,"Mean ratings by age_band and gender.png",sep = ""))


rating_genre <- df %>% 
  gather(genre,is_off,unknown:western) %>% 
  filter(is_off == T) %>% 
  mutate(rating = as.factor(rating)) %>% 
  select(-is_off)

#check if reatungs corelated with means
ggplot(rating_genre  ,aes(x=item_imdb_rating_of_ten,y=(item_mean_rating*2),colour= rating)) + geom_point() +
  labs(x = "IMDB mean rating",y="Movie mean Rating") + ggtitle("Population mean rating")+ 
  scale_color_discrete(name= 'User ratings')
unlink(paste(graph_dir,"Mean ratings compared to IMDB.png",sep = ""))
ggsave(paste(graph_dir,"Mean ratings compared to IMDB.png",sep = ""))


#check ths=is over all genres by gender
i <- 2
while(i <= length(genres)){
  title <- paste(genres[i:(i+3)],collapse =",")
  g <- ggplot(rating_genre %>% filter(genre %in% genres[i:(i+3)]) ,aes(x=item_imdb_rating_of_ten,y=item_mean_rating,colour= gender)) + geom_point() +
    labs(x = "IMDB mean rating",y="Movie mean Rating") + ggtitle(title)+  facet_wrap(~genre)+
    scale_color_discrete(name= 'User ratings') + theme(legend.position = "bottom")
  print(g)
  unlink(paste(graph_dir,title,"_gender.png",sep = ""))
  ggsave(paste(graph_dir,title,"_gender.png",sep = ""))
  i= i + 4
}

#check ths=is over all genres by rating
i <- 2
while(i <= length(genres)){
  title <- paste(genres[i:(i+3)],collapse =",")
  g <- ggplot(rating_genre %>% filter(genre %in% genres[i:(i+3)]) ,aes(x=item_imdb_rating_of_ten,y=item_mean_rating,colour= rating)) + geom_point() +
    labs(x = "IMDB mean rating",y="Movie mean Rating") + ggtitle(title)+  facet_wrap(~genre)+
    scale_color_discrete(name= 'User ratings') + theme(legend.position = "bottom")
  print(g)
  unlink(paste(graph_dir,title,"_rating.png",sep = ""))
  ggsave(paste(graph_dir,title,"_rating.png",sep = ""))
  i= i + 4
}


#check mean ratings by genre in core and non core group

ggplot(rating_genre %>%
         filter(age >= 18 & age < 45 & gender== "M") %>% 
         select(c(item_imdb_rating_of_ten,user_age_band_item_imdb_mean_rating,genre)) %>% 
         distinct(),aes(x=item_imdb_rating_of_ten,y=user_age_band_item_imdb_mean_rating)) + 
    geom_point() + geom_jitter()+ facet_wrap(.~genre)+
  labs(x = "IMDB mean rating",y="Targeted group mean Rating") + ggtitle("Mean ratings in Males 18-44")+ 
  scale_color_discrete(name= 'Genres')
unlink(paste(graph_dir,"Mean ratings in Males 18-44.png",sep = ""))
ggsave(paste(graph_dir,"Mean ratings in Males 18-44.png",sep = ""))


ggplot(rating_genre %>%
         filter(age < 18 | age > 45 | gender== "F") %>% 
         select(c(item_imdb_rating_of_ten,user_gender_age_band_item_imdb_mean_rating,genre)) %>% 
         distinct(),aes(x=item_imdb_rating_of_ten, y=user_gender_age_band_item_imdb_mean_rating)) + 
  geom_point() + geom_jitter()+ facet_wrap(.~genre)+
  labs(x = "IMDB mean rating",y="Targeted group mean Rating") + ggtitle("Mean ratings not in Males 18-44")+ 
  scale_color_discrete(name= 'Genres')
unlink(paste(graph_dir,"Mean ratings not in Males 18-44.png",sep = ""))
ggsave(paste(graph_dir,"Mean ratings not in Males 18-44.png",sep = ""))

#check ratoign means by state
ggplot((df %>% select(c(State,user_mean_rating,user_id)) %>% distinct()),aes(x=user_mean_rating,y = State)) + geom_density_ridges2() +
  labs(title = "State average ratings",x = "Rating",y = "") 
unlink(paste(graph_dir,"state_mean.png",sep = ""))
ggsave(paste(graph_dir,"state_mean.png",sep = ""))


ggplot(df %>% select(item_imdb_length,item_mean_rating) %>% distinct(),aes(x=item_imdb_length,y = item_mean_rating)) + geom_point() +
  labs(x = "Runtime",y = "Rating") 
unlink(paste(graph_dir,"run_rate.png",sep = ""))
ggsave(paste(graph_dir,"run_rate.png",sep = ""))


ggplot(rating_genre %>%
         select(item_id,item_mean_rating,item_imdb_top_1000_voters_average,genre) %>% 
         filter(genre != 'unknown') %>% 
         distinct()
       ,aes(y = item_mean_rating,x = item_imdb_top_1000_voters_average,colour = genre)) + 
  geom_point() + geom_jitter()+
  labs(y = "Item _mean_rating",x = "IMDB_votes") + scale_color_discrete(name= 'Genres')
unlink(paste(graph_dir,"rating_votes.png",sep = ""))
ggsave(paste(graph_dir,"rating_votes.png",sep = ""))

#check rating measn by mature rating
ggplot((df %>% select(c(item_imdb_mature_rating,user_mean_rating,user_id)) %>% distinct()),aes(x=user_mean_rating,y = item_imdb_mature_rating)) +
  geom_density_ridges2() +
  labs(title = "Mature average ratings",x = "Rating",y = "") 
unlink(paste(graph_dir,"mature_mean.png",sep = ""))
ggsave(paste(graph_dir,"mature_mean.png",sep = ""))

rm(list=ls())



# Read training data from RDS file
movie_data <-readRDS("AT2_train_STUDENT.rds")

# Read 
scrape <- readRDS("scrape.rds")

movie_data$length = 0
for (i in 1:nrow(movie_data)){
  movie_data[i,"length"]=scrape[scrape$movie_id==as.numeric(movie_data[i,"item_id"]),"length"]
}

## SUBSCRIPTIONS
# Find movies with a rating of 5
high_rating_data <- movie_data[movie_data$item_mean_rating >= 4.5,]
high_rating_content <- unique(high_rating_data$movie_title)

# Extracting the ratings made by male users between the ages of 18 and 24
core_high_rating <- high_rating_data[high_rating_data$age >= 18 & high_rating_data$age <= 44 & high_rating_data$gender == "M",]
core_high_content <- unique(core_high_rating$movie_title)

# Plotting Item ID against runtime
ggplot(data = movie_data,aes(x=item_id, y=length)) + geom_point()

# Extracting movies with a short runtime
short_core_data <- core_high_rating[core_high_rating$length <= 135,]
short_core_content <- unique(short_core_data$movie_title) # This gives only NA values

#Inspecting the runtime of movies highly rated by the core userbase
core_high_rating$length

movie_categories <- factor(c("unknown","action","adventure","animation","childrens","comedy","crime","documentary","drama","fantasy","film_noir","horror","musical","mystery","romance","sci_fi","thriller","war","western"))
movie_cat_level <- levels(movie_categories)

for (i in 1:nrow(core_high_rating)){
  for (j in 1:nlevels(movie_categories)){
    if (core_high_rating[i,movie_cat_level[j]]==TRUE){
      core_high_rating[i,"movie_category"] <- movie_cat_level[j]
    }
  }
}

core_high_rating$movie_category <- str_replace(core_high_rating$movie_category, "sci_fi", "sci-fi")

# Plotting number of ratings against movie genre for the core userbase
ggplot(data = core_high_rating,aes(x=movie_category)) + geom_bar() + labs(x = "Movie Genre",
       y = "Number of ratings",
       title = "Number of ratings by core userbase per genre")

## ADS
# Extracting movies with a long runtime
long_runtime_data <- movie_data[!is.na(movie_data$length >= 135),]
long_runtime_movies <- unique(long_runtime_data$movie_title)

# Finding the long running movies with high rating by core user base
long_core_data <- core_high_rating[core_high_rating$length >= 135,]
long_core_content <- unique(long_core_data$movie_title)


```


# Item based collab filtering
```{r}

#subset out only user ids, item ids and ratings from data
train <- readRDS("./AT2_train_STUDENT.rds")
train_ratings <- train %>% 
  select(user_id, item_id, rating) %>% 
  pivot_wider(names_from = item_id, values_from = rating) %>% #pivot to user item matrix
  column_to_rownames(var = "user_id")

#convert to matrix
train_matrix <- as.matrix(train_ratings)

#convert to recommenderlab realRatingMatrix
train_rrm <- as(train_matrix, "realRatingMatrix")

# params, k, method, normalize, normalize_sim_matrix, alpha, na_as_zero

#train icbf model
ibcf_rec <- Recommender(train_rrm, method = "IBCF", param=list(k = 315, method = "Pearson", alpha = 0.5))

#make predictions
preds_ibcf <- predict(ibcf_rec, train_rrm, type="ratingMatrix")

#calculate inset accuracy
calcPredictionAccuracy(preds_ibcf, train_rrm)

# tune k, RMSEMIN 0.81427 @ k315  RMSE 0.903@ k675

#bring predictions back to dataframe format
preds_ibcf_mat <- as(preds_ibcf, "matrix")
preds_ibcf_df <- as.data.frame(preds_ibcf_mat)

#structure predictions in user, item, rating format
preds_piv_ibcf <- preds_ibcf_df
preds_piv_ibcf <- preds_piv_ibcf %>% 
  rownames_to_column(var = "user_id") %>% 
  pivot_longer(cols = -user_id, names_to = "item_id", values_to = "rating")
```


```{r}
test <- readRDS("./AT2_test_STUDENT.rds")

#load test and selecct same columsn as train
test_rat <- test %>% 
  select(user_id, item_id) %>% 
  mutate(user_item = paste(user_id,item_id,sep = "_"))

#use prediction dataframe to match predictions with testset
test_rat_ibcf <- left_join(test_rat, preds_piv_ibcf, by = c("user_id", "item_id"))

#check for na (na's decrease with high k param for ibcf)
test_na <- na.omit(test_rat)

str(test_rat)
```

#user based collab filtering
```{r}
# params, method, nn, sample, normalize
ubcf_rec <- Recommender(train_rrm, method = "UBCF", param=list(normalize = "center",method="Pearson", nn = 5))

#same process for ubcf

preds_ubcf <- predict(ubcf_rec, train_rrm, type="ratingMatrix")

calcPredictionAccuracy(preds_ubcf,train_rrm)

preds_ubcf_mat <- as(preds_ubcf, "matrix")
preds_ubcf_df <- as.data.frame(preds_ubcf_mat)

preds_piv_ubcf <- preds_ubcf_df
preds_piv_ubcf <- preds_piv_ubcf %>% 
  rownames_to_column(var = "user_id") %>% 
  pivot_longer(cols = -user_id, names_to = "item_id", values_to = "rating")

test_rat_ubcf <- left_join(test_rat, preds_piv_ubcf, by = c("user_id", "item_id"))
test_rat_ubcf[test_rat_ubcf$rating > 5, "rating"] <- 5
test_rat_ubcf[test_rat_ubcf$rating < 0, "rating"] <- 0 

ubcf_out <- test_rat_ubcf %>% 
  select(user_item, rating)

write_csv(ubcf_out, "./predictions/ubcfv2.csv")

# test_pred@data@x[test_pred@data@x[] < 0] <- 0
# test_pred@data@x[test_pred@data@x[] > 5] <- 5
```

# $SVDF_realRatingMatrix

```{r}
# params k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 200, min_improvement = 1e-06, normalize = "centre" verbose = FALSE

# same process for SVDfunk

svdf_rec <- Recommender(train_rrm, method = "SVDF", param=list(k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 1000, min_improvement = 1e-07, verbose = TRUE))

# Tune, RMSEMIN @ , RMSE0.9@ 

preds_svdf <- predict(svdf_rec, train_rrm, type="ratingMatrix")

calcPredictionAccuracy(preds_svdf,train_rrm)

#create recommender evaluation scheme

svde <- evaluationScheme(train_rrm, method="split", train=0.8, given=-4, goodRating=5)

#manual tuning
#create models

svdf_rec1 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 1000, min_improvement = 1e-07, verbose = TRUE))
svdf_rec2 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 200, min_improvement = 1e-07, verbose = TRUE))
ibcf_rec1 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 50, method = "Pearson", alpha = 0.5))
ibcf_rec2 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 100, method = "Pearson", alpha = 0.5))
ibcf_rec3 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 200, method = "Pearson", alpha = 0.5))
ibcf_rec4 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 300, method = "Pearson", alpha = 0.5))
ibcf_rec5 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 400, method = "Pearson", alpha = 0.5))
ibcf_rec6 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 500, method = "Pearson", alpha = 0.5))
ibcf_rec7 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 600, method = "Pearson", alpha = 0.5))
ibcf_rec8 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 700, method = "Pearson", alpha = 0.5))
ibcf_rec9 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 800, method = "Pearson", alpha = 0.5))
ibcf_rec10 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 900, method = "Pearson", alpha = 0.5))
ibcf_rec11 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 1000, method = "Pearson", alpha = 0.5))
ibcf_rec12 <- Recommender(getData(svde, "train"), method = "IBCF", param=list(k = 1100, method = "Pearson", alpha = 0.5))
svdf_rec3 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=6, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec4 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=7, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec5 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=8, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec6 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=9, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec7 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=10, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec8 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=11, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec9 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=12, gamma = 0.018, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec10 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=6, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec11 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=7, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec12 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=8, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec13 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=9, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec14 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=10, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec15 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=11, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec16 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=12, gamma = 0.012, lambda = 0.001, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec17 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=7, gamma = 0.015, lambda = 0.0008, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec18 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=8, gamma = 0.015, lambda = 0.0008, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec19 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=9, gamma = 0.015, lambda = 0.0015, min_epochs = 50, max_epochs = 225, min_improvement = 1e-07, verbose = TRUE))
svdf_rec20 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=7, gamma = 0.03, lambda = 0.001, min_epochs = 50, max_epochs = 250, min_improvement = 1e-07, verbose = TRUE))

#k=12 seems good

# svdf_rec18 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=7, gamma = 0.03, lambda = 0.001, min_epochs = 50, max_epochs = 250?400, min_improvement = 1e-07, verbose = TRUE)) #9.30
# svdf_rec2 <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 200, min_improvement = 1e-07, verbose = TRUE)) #9.27


#make predictions

svdfp1 <- predict(svdf_rec1, getData(svde, "known"), type="ratings")
svdfp2 <- predict(svdf_rec2, getData(svde, "known"), type="ratings")
ibp1 <- predict(ibcf_rec1, getData(svde, "known"), type="ratings")
ibp2 <- predict(ibcf_rec2, getData(svde, "known"), type="ratings")
ibp3 <- predict(ibcf_rec3, getData(svde, "known"), type="ratings")
ibp4 <- predict(ibcf_rec4, getData(svde, "known"), type="ratings")
ibp5 <- predict(ibcf_rec5, getData(svde, "known"), type="ratings")
ibp6 <- predict(ibcf_rec6, getData(svde, "known"), type="ratings")
ibp7 <- predict(ibcf_rec7, getData(svde, "known"), type="ratings")
ibp8 <- predict(ibcf_rec8, getData(svde, "known"), type="ratings")
ibp9 <- predict(ibcf_rec9, getData(svde, "known"), type="ratings")
ibp10 <- predict(ibcf_rec10, getData(svde, "known"), type="ratings")
ibp11 <- predict(ibcf_rec11, getData(svde, "known"), type="ratings")
ibp12 <- predict(ibcf_rec12, getData(svde, "known"), type="ratings")
svdfp3 <- predict(svdf_rec3, getData(svde, "known"), type="ratings")
svdfp4 <- predict(svdf_rec4, getData(svde, "known"), type="ratings")
svdfp5 <- predict(svdf_rec5, getData(svde, "known"), type="ratings")
svdfp6 <- predict(svdf_rec6, getData(svde, "known"), type="ratings")
svdfp7 <- predict(svdf_rec7, getData(svde, "known"), type="ratings")
svdfp8 <- predict(svdf_rec8, getData(svde, "known"), type="ratings")
svdfp9 <- predict(svdf_rec9, getData(svde, "known"), type="ratings")
svdfp10 <- predict(svdf_rec10, getData(svde, "known"), type="ratings")
svdfp11 <- predict(svdf_rec11, getData(svde, "known"), type="ratings")
svdfp12 <- predict(svdf_rec12, getData(svde, "known"), type="ratings")
svdfp13 <- predict(svdf_rec13, getData(svde, "known"), type="ratings")
svdfp14 <- predict(svdf_rec14, getData(svde, "known"), type="ratings")
svdfp15 <- predict(svdf_rec15, getData(svde, "known"), type="ratings")
svdfp16 <- predict(svdf_rec16, getData(svde, "known"), type="ratings")
svdfp17 <- predict(svdf_rec17, getData(svde, "known"), type="ratings")
svdfp18 <- predict(svdf_rec18, getData(svde, "known"), type="ratings")
svdfp19 <- predict(svdf_rec19, getData(svde, "known"), type="ratings")
svdfp20 <- predict(svdf_rec20, getData(svde, "known"), type="ratings")

#calculate errors

errormods <- rbind(sv1 = calcPredictionAccuracy(svdfp1, getData(svde, "unknown")),
               sv2 = calcPredictionAccuracy(svdfp2, getData(svde, "unknown")),
               ib1 = calcPredictionAccuracy(ibp1, getData(svde, "unknown")),
               ib2 = calcPredictionAccuracy(ibp2, getData(svde, "unknown")),
               ib3 = calcPredictionAccuracy(ibp3, getData(svde, "unknown")),
               ib4 = calcPredictionAccuracy(ibp4, getData(svde, "unknown")),
               ib5 = calcPredictionAccuracy(ibp5, getData(svde, "unknown")),
               ib6 = calcPredictionAccuracy(ibp6, getData(svde, "unknown")),
               ib7 = calcPredictionAccuracy(ibp7, getData(svde, "unknown")),
               ib8 = calcPredictionAccuracy(ibp8, getData(svde, "unknown")),
               ib9 = calcPredictionAccuracy(ibp9, getData(svde, "unknown")),
               ib10 = calcPredictionAccuracy(ibp10, getData(svde, "unknown")),
               ib11 = calcPredictionAccuracy(ibp11, getData(svde, "unknown")),
               ib12 = calcPredictionAccuracy(ibp12, getData(svde, "unknown")),
               sv3 = calcPredictionAccuracy(svdfp3, getData(svde, "unknown")),
               sv4 = calcPredictionAccuracy(svdfp4, getData(svde, "unknown")),
               sv5 = calcPredictionAccuracy(svdfp5, getData(svde, "unknown")),
               sv6 = calcPredictionAccuracy(svdfp6, getData(svde, "unknown")),
               sv7 = calcPredictionAccuracy(svdfp7, getData(svde, "unknown")),
               sv8 = calcPredictionAccuracy(svdfp8, getData(svde, "unknown")),
               sv9 = calcPredictionAccuracy(svdfp9, getData(svde, "unknown")),
               sv10 = calcPredictionAccuracy(svdfp10, getData(svde, "unknown")),
               sv11 = calcPredictionAccuracy(svdfp11, getData(svde, "unknown")),
               sv12 = calcPredictionAccuracy(svdfp12, getData(svde, "unknown")),
               sv13 = calcPredictionAccuracy(svdfp13, getData(svde, "unknown")),
               sv14 = calcPredictionAccuracy(svdfp14, getData(svde, "unknown")),
               sv15 = calcPredictionAccuracy(svdfp15, getData(svde, "unknown")),
               sv16 = calcPredictionAccuracy(svdfp16, getData(svde, "unknown")),
               sv17 = calcPredictionAccuracy(svdfp17, getData(svde, "unknown")),
               sv18 = calcPredictionAccuracy(svdfp18, getData(svde, "unknown")),
               sv19 = calcPredictionAccuracy(svdfp19, getData(svde, "unknown")),
               sv20 = calcPredictionAccuracy(svdfp20, getData(svde, "unknown"))
               )

errormods

svdf_rec <- Recommender(train_rrm, method = "SVDF", param=list(k=10, gamma = 0.025, lambda = 0.001, min_epochs = 50, max_epochs = 200, min_improvement = 1e-07, verbose = TRUE)) #9.27

# save(svdf_rec, file = "./models/svdf_epic")

#make predictions
preds_svdf <- predict(svdf_rec, train_rrm, type="ratingMatrix")

preds_svdf_mat <- as(preds_svdf, "matrix")
preds_svdf_df <- as.data.frame(preds_svdf_mat)

preds_piv_svdf<- preds_svdf_df
preds_piv_svdf <- preds_svdf_df %>% 
  rownames_to_column(var = "user_id") %>% 
  pivot_longer(cols = -user_id, names_to = "item_id", values_to = "rating")

test_rat_svdf <- left_join(test_rat, preds_piv_svdf, by = c("user_id", "item_id"))

test_rat_svdf[test_rat_svdf$rating > 5, "rating"] <- 5
test_rat_svdf[test_rat_svdf$rating < 0, "rating"] <- 0 

svdf_out <- test_rat_svdf %>% 
  select(user_item, rating)

write_csv(svdf_out, "./predictions/svdfv2.csv")
```

# super out
```{r}

# test combos

#attempt to improve by combining ibcf and svdf (svdf alone had better outcomes)

train_out <- train

train_rat <- train_out %>% 
  select(user_id, item_id, rating_t = rating) %>% 
  mutate(user_item = paste(user_id,item_id,sep = "_"))

train_rat_svdf <- left_join(train_rat, preds_piv_svdf, by = c("user_id", "item_id"))
train_rat_ibcf <- left_join(train_rat, preds_piv_ibcf, by = c("user_id", "item_id"))

preds_best_train <- train_rat_svdf
preds_best_train$ibcf <- train_rat_ibcf$rating
preds_best_train[is.na(preds_best_train$ibcf) == FALSE, "rating"] <- preds_best_train[is.na(preds_best_train$ibcf) == FALSE, "ibcf"]

preds_best_train[preds_best_train$rating > 5, "rating"] <- 5
preds_best_train[preds_best_train$rating < 0, "rating"] <- 0 

RMSE(preds_best_train$rating_t, preds_best_train$rating)
```


# evaluation and comparison

```{r, eval = FALSE}

#compare a variety of model types
scheme <- evaluationScheme(ur_rrm, method="cross-validation", train = 0.8, k=5, given=-10, goodRating=4)

algorithms <- list(
  "random items" = list(name="RANDOM", param=NULL),
  "popular items" = list(name="POPULAR", param=NULL),
  "user-based CF" = list(name="UBCF", param=list(nn=50)),
  "item-based CF" = list(name="IBCF", param=list(k=50)),
  "SVD approximation" = list(name="SVD", param=list(k = 50)),
  "SVD Funk" = list(name="SVDF", param=list(k = 50))
)
results <- evaluate(scheme, algorithms, type = "ratings")

plot(results, ylim = c(0,100))
```
```{r}
recommenderRegistry$get_entry_names()

recommenderRegistry$get_entry("IBCF", dataType = "realRatingMatrix")
recommenderRegistry$get_entry("UBCF", dataType = "realRatingMatrix")
recommenderRegistry$get_entry("SVDF", dataType = "realRatingMatrix")

# params k=10, gamma = 0.015, lambda = 0.001, min_epochs = 50, max_epochs = 200, min_improvement = 1e-06, normalize = "centre" verbose = FALSE
```

```{r}
#using bayes optimisation to optimise svdf hyperparameters

library(rBayesianOptimization)
library(ParBayesianOptimization)
library(doParallel)
library(recommenderlab)

#create evaluation scheme

svde <- evaluationScheme(train_rrm, method="split", train=0.8, given=-4, goodRating=5)

#function for optimisation by bayesopt

svdfbayes <- function (kk, gam, lam, minep, maxep, minimp) {
  r <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=kk, gamma = gam, lambda = lam, min_epochs = minep, max_epochs = maxep, min_improvement = minimp, verbose = FALSE))
  p <- predict(r, getData(svde, "known"), type="ratings")
  c <- -(calcPredictionAccuracy(p, getData(svde, "unknown"))[1]) #use negative RMSE and bayesopt maximizes score
  
  pmat <- as(p, "matrix")
  pdf <- as.data.frame(pmat)
  
  list(Score = c, Pred = pdf) #output must be list with Score
}

#set outer bounds for each parameter

svdfbounds <- list(
  kk = c(4,40),
  gam = c(0.001, 0.05),
  lam = c(0.0001,0.005),
  minep = c(10,70),
  maxep = c(80,1000),
  minimp = c(0.0000001,0.00001)
  
)
## intial single threaded option
# start <- proc.time()
# 
# opt <- BayesianOptimization(svdfbayes, bounds = svdfbounds, init_grid_dt = NULL, init_points = 8, n_iter = 4, acq = "ucb", kappa = 2.576, eps = 0, verbose = TRUE)
# 
#   end <- proc.time() - start
#   end_time <- as.numeric((paste(end[3])))
  
#multithread using parbayes
svdfbayes_par <- function (kk, gam, lam, minep, maxep, minimp) {
  r <- Recommender(getData(svde, "train"), method = "SVDF", param=list(k=kk, gamma = gam, lambda = lam, min_epochs = minep, max_epochs = maxep, min_improvement = minimp, verbose = FALSE))
  p <- predict(r, getData(svde, "known"), type="ratings")
  c <- -(calcPredictionAccuracy(p, getData(svde, "unknown"))[1])
  
  # pmat <- as(p, "matrix")
  # pdf <- as.data.frame(pmat)
  
  return(list(Score = c))
}


  registerDoParallel(cores = 3)
  
  
  # use best params from opt
  start <- proc.time()
opt <- bayesOpt(svdfbayes_par, bounds = svdfbounds, initPoints = 24, iters.n = 48, iters.k = 6, acq = "ucb", kappa = 2.576, eps = 0, verbose = TRUE, parallel = TRUE)

  end <- proc.time() - start
  end_time <- as.numeric((paste(end[3])))
  
  getBestPars(opt,1)
  opt$scoreSummary
  
  save(opt, file = "./models/baysopt1.RData")
  
  svdf_opt <- Recommender(train_rrm, method = "SVDF", param=list(k=5.230934, gamma = 0.02670225, lambda = 0.00154614, min_epochs = 65.41348, max_epochs = 494.7491, min_improvement = 3.034796e-07, verbose = TRUE))
  
  preds_svdf <- predict(svdf_opt, train_rrm, type="ratingMatrix")

preds_svdf_mat <- as(preds_svdf, "matrix")
preds_svdf_df <- as.data.frame(preds_svdf_mat)

preds_piv_svdf<- preds_svdf_df
preds_piv_svdf <- preds_svdf_df %>% 
  rownames_to_column(var = "user_id") %>% 
  pivot_longer(cols = -user_id, names_to = "item_id", values_to = "rating")

test_rat_svdf <- left_join(test_rat, preds_piv_svdf, by = c("user_id", "item_id"))

test_rat_svdf[test_rat_svdf$rating > 5, "rating"] <- 5
test_rat_svdf[test_rat_svdf$rating < 0, "rating"] <- 0 

svdf_out <- test_rat_svdf %>% 
  select(user_item, rating)

write_csv(svdf_out, "./predictions/svdf_opt.csv")
  
  
```





